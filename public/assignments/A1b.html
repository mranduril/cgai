<style>
    /* Custom styles for headings */
    .h1-custom {
        font-size: 2.25rem; /* equivalent to text-4xl */
        font-weight: 700; /* equivalent to font-bold */
        margin-bottom: 1.5rem; /* equivalent to mb-6 */
    }

    .h2-custom {
        font-size: 1.5rem; /* equivalent to text-2xl */
        font-weight: 600; /* equivalent to font-semibold */
        margin-top: 1.5rem; /* equivalent to mt-6 */
        margin-bottom: 1rem; /* equivalent to mb-4 */
    }

    .h3-custom {
        font-size: 1.25rem; /* equivalent to text-xl */
        font-weight: 500; /* equivalent to font-medium */
        margin-top: 1rem; /* equivalent to mt-4 */
        margin-bottom: 0.5rem; /* equivalent to mb-2 */
    }

    .h4-custom {
        font-size: 1.05rem; /* equivalent to text-xl */
        font-weight: 500; /* equivalent to font-medium */
        margin-top: 1rem; /* equivalent to mt-4 */
        margin-bottom: 0.5rem; /* equivalent to mb-2 */
    }

    /* Styling for code elements */
    .code-inline {
        font-family: 'Fira Code', Consolas, 'Courier New', monospace;
        font-size: 1.1rem;
        font-weight: bold;
    }

    .link-inline {
        text-decoration: underline;  /* Ensures the links are underlined */
        color: #1d4ed8;              /* Sets the blue color for the links */
        font-family: 'Fira Code', Consolas, 'Courier New', monospace;
        font-size: 1.1rem;
        font-weight: bold;
    }

    /* Fixing the problem with ul and li elements */
    ul {
        list-style-type: disc;  /* Ensures the default bullet style */
        margin-left: 2rem;      /* Adds left indentation for the list */
        padding-left: 1.5rem;   /* Adds extra padding inside the list */
    }

    li {
        margin-bottom: 0.5rem; /* Adds space between list items */
    }

    .image-container {
        display: flex; 
        justify-content: center; /* Center images */
        gap: 20px; /* Space between images */
    }
    .image-container img {
        width: 50%; /* Adjust width */
        height: auto; /* Maintain aspect ratio */
    }

</style>

<h1 class="h1-custom">
    Assignment 1B: Neural Implicit Surface
</h1>

<p class="mb-4">
    Welcome to the second part of our exploration of SDF! In this section, you will continue practicing coding with implicit functions, this time incorporating neural networks as your new friend! The main task for this assignment consists of two steps: first, you will construct and train a neural SDF model in Python using a Colab Jupyter Notebook. Then, you will render this model using GLSL in our WebGL shader. You will be working on both aspectsâ€”neural network training and shader-based rendering. Let's get started!
</p>

<h2 class="h2-custom">Reading</h2>
<p class="mb-4">
    Before diving into our code, you may refer to our course slides as well as the supplementary reading materials to get a comprehensive understanding of SDF and ray marching. Here is the reading list:
</p>

<ul class="list-disc pl-8 mb-4">
    <li>Course Slides on SDF Representation and Neural Implicit Surface</li>
    <li><a href="https://arxiv.org/abs/1901.05103" class="link-inline">DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation
    </a></li>
    <li><a href="https://www.youtube.com/watch?v=8pwXpfi-0bU" class="link-inline">A Haphazard Tutorial for Making Neural SDFs in Shadertoy</a></li>
    <li><a href="https://www.shadertoy.com/view/wtVyWK" class="link-inline">Neural Stanford Bunny on ShaderToy</a></li>
    <li><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" class="link-inline">PyTorch Official Document (First Four sections)</a></li>
    <li><a href="https://cgai-gatech.vercel.app/tutorial/colab-tutorial" class="link-inline">CGAI Tutorial: Google Colab</a></li>
    <li><a href="https://cgai-gatech.vercel.app/tutorial/pytorch-tutorial" class="link-inline">CGAI Tutorial: Training a Network in PyTorch</a></li>
</ul>

<h2 class="h2-custom">Starter Code</h2>
<p class="mb-4">
    Please visit the following GitHub repository to get our latest starter code: <a href="https://github.com/cg-gatech/cgai" class="link-inline">https://github.com/cg-gatech/cgai</a>. Make sure to run 'git pull' to synchronize the latest version. Make sure you can access the default CGAI web page after starting the npm server. The starter code for this assignment is located in the folder <code class="code-inline">src/app/(assignment)/assignment/A1b</code>. This folder contains several files, including the main page <code class="code-inline">page.tsx</code>, the Jupyter notebook file <code class="code-inline">neural_sdf.ipynb</code>, the GLSL shader <code class="code-inline">fragment.glsl</code>, and several mesh files. Your implementation will focus on <code class="code-inline">neural_sdf.ipynb</code> and <code class="code-inline">fragment.glsl</code>.
</p>

<p class="mb-4">

To view the default initial effect for this assignment, you can either use the navigation bar by clicking Assignments and then Assignment 1b, or directly access the URL: <a href="http://localhost:3000/assignment/A1b" class="link-inline">http://localhost:3000/assignment/A1b</a> (Note that the port number may vary depending on the available ports on your local computer). After successfully completing the setup, you should see a blank window.
</p>

<h2 class="h2-custom">Requirements</h2>
<p class="mb-4">
For this assignment, you are required to implement two main components: generating a neural SDF and rendering it in a GLSL environment using ray marching. You may choose to either first create the neural network by following the substeps in Step I and then visualize it in the GLSL shader in Step II, or complete the rendering functions in Step II first, verify them using the default neural Stanford Bunny model provided in the shader, and then return to implement Step I. The two steps are briefly described as follows.
</p>

<h3 class="h3-custom">Step 1: Neural SDF Creation</h3>
<p class="mb-4">
In this step, you are asked to create a PyTorch dataset class named <code>NeuralSDFDataset</code> which loads a 3D mesh with <code>.obj</code> format and sample data points around it for training. After this, you will create a network to train Neural SDF. Finish the training loop and train your network. Your implementation will focus on <code class="code-inline">neural_sdf.ipynb</code>.
</p>

<h3 class="h4-custom">Step 1.1 Preparation</h3>
<p class="mb-4">    
    Upload the Notebook file <code>neural_sdf.ipynb</code> to Google Colab. We prepared a quick tutorial for you for this step in <code>Tutorials/Google Colab Tutorial</code>, please read it carefully and follow the steps. Make sure to run all the cells before Step 1.2. These cells will install required packages and compile helper functions we shall need later in other steps.
</p>

<h3 class="h4-custom">Step 1.2 NeuralSDFDataset</h3>
<p class="mb-4">    
    In this step, you will implement a <code>NeuralSDFDataset</code> class. We will follow the the way Neural SDF paper sample training points where the majority of points are sampled near the mesh surface while a small amount are sampled in the space of a unit sphere around the shape. We will implement this step by using the <code>mesh_to_sdf</code> package. In our starter code, we've provided the code for loading the mesh with path <code>mesh_path</code> and sample <code>sample_num</code> number of points using <code>sample_sdf_near_surface</code> function from <code>mesh_to_sdf</code> package.
</p></br>

<p class="mb-4"></p>
    <em>[Your implementation]</em> For your implementation, you will need to implement the step to convert sampled points in type <code>numpy ndarray</code> to <code>torch tensor</code> by using the <code>torch.from_numpy</code> function. Since we are using Colab where GPU is available, you will put those tensors to <code>CUDA</code> by using <code>.to(device)</code>. The converted device tensors should be stored in self.points and self.sdf in separate.
</p></br>

<p class="mb-4">
    <em>[Checkpoint]</em> After finishing this step, you can check the correctness of your implementation by plotting the point cloud in the next block. The expected result for a bunny/cow is as below.
</p>    

<div class="image-container">
    <img src="/assignments/A1b_img/bunny.png" alt="Image 1">
    <img src="/assignments/A1b_img/cow.png" alt="Image 2">
</div>


<h3 class="h4-custom">Step 1.3: Network Structure</h3>
<p class="mb-4">    
    After completing the creation of your training dataset, you will implement a neural network class named <code>NeuralSDF</code>. This step consists of two substeps:  
    (1) implementing the constructor and forward function for the sine-based neural network layer defined in <code>SineLayer</code>, and  
    (2) implementing the constructor for the overall network architecture defined in <code>NeuralSDF</code>.
    </br></br>

    <em>Your Implementation (1): <code>SineLayer</code></em></br>
    First, you will complete the constructor of the <code>SineLayer</code> class. This requires creating a Linear layer named <code>self.fc</code> with an input feature size of <code>in_features</code> and an output feature size of <code>out_features</code>.  
    </br>

    Next, you will implement your <code>forward</code> function of <code>SineLayer</code>. Your implementation should handle the following three cases according to the network layer index:  
    </br></br>

    <div class="image-container">
        <img src="/assignments/A1b_img/equation.png" alt="cases" width="auto" height="auto">
    </div>
    </br>

    In these equations: <strong>s</strong> is a number representing the <code>skip_weight</code> parameter, <strong>w0</strong> is a number representing the activation function frequency, and <strong>g(x)</strong> represents the fully connected layer in the neural network. You will use the flags <code>is_first</code> or <code>is_last</code> to determine whether a network layer passed into the function is the first or last layer or not.  
    </br></br>
    
    <em>Your Implementation (2): <code>NeuralSDF</code></em></br>
    After implementing the <code>SineLayer</code> class, you will proceed to define the network structure in the <code>NeuralSDF</code> class. This step requires using your previously implemented <code>SineLayer</code> class to construct the network architecture.  

    Your task is to append each layer to the list defined by <code>self.network</code>, following these guidelines:
     
    <ul>
        <li><strong>First Layer:</strong> Use the <code>is_first</code> flag to mark it as the first layer. Create a network layer using the <code>SineLayer</code> class with an input feature size of <code>in_features</code> and an output feature size of <code>hidden_features</code>.</li>
        <li><strong>Hidden Layers:</strong> Create <code>hidden_layers</code> number of hidden layers, each with both input and output feature sizes set to <code>hidden_features</code>. The skip weight should be set to <code>skip_weight=sqrt(i+1)</code>, where <code>i</code> is the index of the current hidden layer.</li>
        <li><strong>Last Layer:</strong> Create the final layer with an input feature size of <code>hidden_features</code> and an output feature size of 1. Use the <code>is_last</code> flag to mark it as the last layer.</li>
    </ul>
</p>

<h3 class="h4-custom">Step 1.4: Train Your Network</h3>
<p class="mb-4">
    After creating the network structure, your next task is to train your neural network. You will use Mean Squared Error (MSE) as the loss function.  
    At the start of each iteration, ensure that you zero the gradients in your optimizer. At the end of each iteration, propagate the loss backward to update the network parameters. Read the PyTorch tutorials from both the <a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" class="link-inline">PyTorch official website</a> and <a href="https://cgai-gatech.vercel.app/tutorial/pytorch-tutorial" class="link-inline">our CGAI website</a>.</br>
    </br>
    Now, start training your network! You should observe a gradual decrease in loss in the printed output. The entire training process is expected to converge after approximately 10,000 epochs (~20 print iterations), which usually takes a few minutes on Colab.  
    </br></br>
    Note:We have intentionally reduced the network size for faster training. Feel free to increase the network scale for better results by adjusting the provided hyperparameters before calling the <code>train_neuralSDF</code> function.
</p>

<h3 class="h3-custom">Step 2: Neural SDF Rendering</h3>

<h3 class="h4-custom">Step 2.1: Copy Network Weights to Shader</h3>
<p class="mb-4">
    Run the final cell in your notebook after the training loop completes. Copy the printed output from your notebook and paste it into <code>sdfBunny</code> for the bunny or <code>sdfCow</code> for the cow.  
    You should now see your trained results displayed on the screen. If you modify the code, remember to refresh the browser to apply the changes.
</p>

<h3 class="h4-custom">Step 2.2: Scene SDF</h3>
<p class="mb-4">
In this step, you are tasked with constructing the scene's SDF using the two neural SDF objects. You will need to position these two objects appropriately according to the instructions in the starter code comment. The final SDF function should return the minimum distance to any neural implicit surface in the scene.
</p>

<h3 class="h4-custom">Step 2.3: Ray Marching</h3>
<p class="mb-4">
In this step, you are asked to implement the ray marching algorithm to render the SDF scene. You are allowed to reuse your previous implementation in A1a for this function.
</p>

<h3 class="h4-custom">Step 2.4: Normal Calculation</h3>
<p class="mb-4">
In this step, you will calculate the surface normal at a given point using the finite difference method. You are allowed to reuse your previous implementation in A1a for this function.
</p>

<h3 class="h4-custom">Step 2.5: Lighting and Coloring</h3>
<p class="mb-4">
In this step, you are asked to color the objects to achieve realistic lighting effects. You are also tasked to assign a unique color to each neural SDF object in the scene based on its position or type. <em>We do not ask for a perfect match of our given video. You may pick any color you like for the rendering of these two objects.</em>

Once you have implemented all these steps, you should be able to observe the two neural SDF models (bunny and cow) as shown in the video below. 
</p>

<video controls autoplay loop muted>
    <source src="/assignments/a1b-ref.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video>

<h2 class="h2-custom">Creative Expression</h2>
In the Creative Expression section of this assignment, you are encouraged to train your customized neural SDF model. You may either use one of the meshes provided in our starter code, or you may download a new mesh and train its neural SDF model in Colab. You may adjust the hyperparameters of the network (e.g., the number of layers, the number of weights, etc.) to improve the appearance of your neural SDF model. The creative expression theme for this assignment is <strong>A Tangible Neural Network</strong>.

<h2 class="h2-custom">Submission</h2>
<ul class="list-disc pl-8 mb-4">
    <li>Your source code <code class="code-inline">neural_sdf.ipynb</code> and <code class="code-inline">fragment.glsl</code></li>
    <li>Your default ray-marching video after completing the six steps</li>
    <li>Your customized video with your own neural SDF objects for creative expression</li>
    <li>A concise technical explanation of your implementation</li>
</ul>

<h2 class="h2-custom">Grading</h2>
<p>This assignment is worth a total of 8 points, with the grading criteria outlined as follows:</p>
<ul class="list-disc pl-8 mb-4">
    <li>
        <strong>Technical Contribution (7 points):</strong> The core of the grading is based on the correct implementation of the neural network architectures and their rendering. The distribution of points is as follows:
        <ul class="list-disc pl-8 mb-4">
            <li>Step 1: 4 points </li>
            <li>Step 2: 3 points </li>
        </ul>
    </li>
    <li>
        <strong>Creative Expression (1 point):</strong> This aspect focuses on your ability to create new SDF objects with neural networks.
    </li>
</ul>

<h2 class="h2-custom">Sharing Your Work</h2>
<p>You are encouraged to share your graphical work with the class. If you want to do so, please upload your image to the Ed Discussion post <strong>A1B Gallery: A Tangible Neural Network</strong>. This is an excellent opportunity to engage with your peers and gain recognition for your work. Share with us the blobby world you create!</p>
