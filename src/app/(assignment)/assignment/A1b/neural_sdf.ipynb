{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7328294",
   "metadata": {},
   "source": [
    "## Step 1.1: Install Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9815e45-57bf-4565-8670-6d91c8bdb35f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9815e45-57bf-4565-8670-6d91c8bdb35f",
    "outputId": "eecd5817-1a38-4eea-8bb7-f64dc79603b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvirtualdisplay\n",
      "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: pyvirtualdisplay\n",
      "Successfully installed pyvirtualdisplay-3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mesh_to_sdf\n",
      "  Downloading mesh_to_sdf-0.0.15-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pyopengl (from mesh_to_sdf)\n",
      "  Downloading PyOpenGL-3.1.9-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pyrender (from mesh_to_sdf)\n",
      "  Downloading pyrender-0.1.45-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting scikit-image (from mesh_to_sdf)\n",
      "  Downloading scikit_image-0.25.2-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting scikit-learn (from mesh_to_sdf)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting freetype-py (from pyrender->mesh_to_sdf)\n",
      "  Downloading freetype_py-2.5.1-py3-none-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting imageio (from pyrender->mesh_to_sdf)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: networkx in d:\\conda\\envs\\hml\\lib\\site-packages (from pyrender->mesh_to_sdf) (3.3)\n",
      "Requirement already satisfied: numpy in d:\\conda\\envs\\hml\\lib\\site-packages (from pyrender->mesh_to_sdf) (2.2.2)\n",
      "Requirement already satisfied: Pillow in d:\\conda\\envs\\hml\\lib\\site-packages (from pyrender->mesh_to_sdf) (11.1.0)\n",
      "Collecting pyglet>=1.4.10 (from pyrender->mesh_to_sdf)\n",
      "  Downloading pyglet-2.1.2-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting pyopengl (from mesh_to_sdf)\n",
      "  Downloading PyOpenGL-3.1.0.zip (2.2 MB)\n",
      "     ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 2.2/2.2 MB 20.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting scipy (from pyrender->mesh_to_sdf)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: six in d:\\conda\\envs\\hml\\lib\\site-packages (from pyrender->mesh_to_sdf) (1.17.0)\n",
      "Collecting trimesh (from pyrender->mesh_to_sdf)\n",
      "  Downloading trimesh-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->mesh_to_sdf)\n",
      "  Downloading tifffile-2025.2.18-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in d:\\conda\\envs\\hml\\lib\\site-packages (from scikit-image->mesh_to_sdf) (24.2)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->mesh_to_sdf)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->mesh_to_sdf)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->mesh_to_sdf)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading mesh_to_sdf-0.0.15-py3-none-any.whl (14 kB)\n",
      "Downloading pyrender-0.1.45-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 20.3 MB/s eta 0:00:00\n",
      "Downloading scikit_image-0.25.2-cp312-cp312-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 4.7/12.9 MB 22.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.9/12.9 MB 18.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.3/12.9 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 19.7 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 22.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 22.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 21.7 MB/s eta 0:00:00\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading pyglet-2.1.2-py3-none-any.whl (961 kB)\n",
      "   ---------------------------------------- 0.0/962.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 962.0/962.0 kB 22.6 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.5/40.9 MB 22.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.2/40.9 MB 22.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 13.6/40.9 MB 22.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 18.4/40.9 MB 22.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.8/40.9 MB 22.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 27.8/40.9 MB 22.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.2/40.9 MB 22.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/40.9 MB 22.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  40.9/40.9 MB 22.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 21.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tifffile-2025.2.18-py3-none-any.whl (226 kB)\n",
      "Downloading freetype_py-2.5.1-py3-none-win_amd64.whl (814 kB)\n",
      "   ---------------------------------------- 0.0/814.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 814.6/814.6 kB 36.8 MB/s eta 0:00:00\n",
      "Downloading trimesh-4.6.3-py3-none-any.whl (707 kB)\n",
      "   ---------------------------------------- 0.0/707.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 707.6/707.6 kB 27.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: pyopengl\n",
      "  Building wheel for pyopengl (setup.py): started\n",
      "  Building wheel for pyopengl (setup.py): finished with status 'done'\n",
      "  Created wheel for pyopengl: filename=PyOpenGL-3.1.0-py3-none-any.whl size=1749328 sha256=2c1d893af9b037dca70f650f8e3a76b0be315f0e01d2652ece3e84c69db36cd7\n",
      "  Stored in directory: c:\\users\\anduril\\appdata\\local\\pip\\cache\\wheels\\5c\\d0\\77\\e69597cdbcb72ea27345036f549a737909bcf17c39789472ce\n",
      "Successfully built pyopengl\n",
      "Installing collected packages: pyopengl, trimesh, tifffile, threadpoolctl, scipy, pyglet, lazy-loader, joblib, imageio, freetype-py, scikit-learn, scikit-image, pyrender, mesh_to_sdf\n",
      "Successfully installed freetype-py-2.5.1 imageio-2.37.0 joblib-1.4.2 lazy-loader-0.4 mesh_to_sdf-0.0.15 pyglet-2.1.2 pyopengl-3.1.0 pyrender-0.1.45 scikit-image-0.25.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0 tifffile-2025.2.18 trimesh-4.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mesh_to_sdf\n",
    "!apt-get install xvfb\n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd34ee-1d7b-47f7-b1c0-9b8bebe3c410",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78dd34ee-1d7b-47f7-b1c0-9b8bebe3c410",
    "outputId": "1052f7fd-6807-4d78-f708-19ac97516e7b"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1.1: Install Necessary Packages and Libraries\n",
    "\"\"\"\n",
    "\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from mesh_to_sdf import sample_sdf_near_surface\n",
    "import trimesh\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476f642",
   "metadata": {},
   "source": [
    "## Step 1.2 Prepare Training Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb098a6-acb2-435e-affd-1f94d2385ec7",
   "metadata": {
    "id": "0cb098a6-acb2-435e-affd-1f94d2385ec7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1.2: Prepare the Training Dataset from Input Mesh\n",
    "\"\"\"\n",
    "\n",
    "class NeuralSDFDataset(Dataset):\n",
    "    def __init__(self, mesh_path, sample_num, device='cuda'):\n",
    "        \"\"\"\n",
    "        In this function, we first use a package called `trimesh` (it's already imported in Step 1.1) to load an `.obj` file with path <code>mesh_path</code>\n",
    "        We then sample sample_num points around the surface by calling method `sample_sdf_near_surface`.\n",
    "        \n",
    "        Your task is to convert the sampled points and their sdf values (with the type of `numpy ndarray`) to torch tensors by calling the `torch.from_numpy` function.\n",
    "        After conversion, you will send those tensors to CUDA GPU by calling the `.to(device)` function.\n",
    "        The converted device tensors should be stored in self.points and self.sdf in separate.\n",
    "        \"\"\"\n",
    "        mesh = trimesh.load(mesh_path)\n",
    "        points, sdf = sample_sdf_near_surface(mesh, number_of_points=sample_num)\n",
    "\n",
    "        ### you implementation starts\n",
    "        \n",
    "        ### you implementation ends\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1 # we are not using this\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.points, self.sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e00e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This block is a checkpoint for you Step 1.2 implementation. Run the block to check the plot of the sample point distribution and make sure it is consistent with the input shape.\n",
    "There is no implementation requirement within this block. \n",
    "\"\"\"\n",
    "\n",
    "### Helper method for test result of the sampled points from your dataset class.\n",
    "def test_dataset(sdf_loader_test):\n",
    "  points, sdf = next(iter(sdf_loader_test))\n",
    "  points =  points.cpu().detach().numpy().squeeze(0)\n",
    "  sdf = sdf.cpu().detach().numpy().squeeze()\n",
    "  norm = plt.Normalize(vmin=np.min(sdf), vmax=np.max(sdf))\n",
    "  colors = plt.cm.coolwarm(norm(sdf))\n",
    "  fig = plt.figure(figsize=(8, 6))\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "  sc = ax.scatter(points[:, 0], points[:, 1], points[:, 2], c=sdf, cmap='coolwarm', marker='o')\n",
    "\n",
    "  cbar = plt.colorbar(sc, ax=ax, shrink=0.5)\n",
    "  cbar.set_label(\"SDF Value\")\n",
    "\n",
    "  ax.set_xlabel(\"X\")\n",
    "  ax.set_ylabel(\"Y\")\n",
    "  ax.set_zlabel(\"Z\")\n",
    "  ax.set_title(\"3D Point Cloud Visualization with SDF Values\")\n",
    "  ax.view_init(elev=0, azim=0)\n",
    "  plt.show()\n",
    "\n",
    "  \n",
    "sample_num = 10000\n",
    "device='cuda'\n",
    "mesh_path=\"cow.obj\" ### Change to bunny.obj if needed.\n",
    "\n",
    "sdf_test = NeuralSDFDataset(mesh_path, sample_num, device=device)\n",
    "sdf_loader_test = DataLoader(sdf_test, num_workers=0)\n",
    "test_dataset(sdf_loader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d9f5e",
   "metadata": {},
   "source": [
    "## Step 1.3 Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db29c56f-6b6c-47f6-8ba5-c40fb6741742",
   "metadata": {
    "id": "db29c56f-6b6c-47f6-8ba5-c40fb6741742"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1.3: Neural Network Structure for SDF Representation\n",
    "\"\"\"\n",
    "\n",
    "class SineLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Default sin activation frequency w0 is set to be 30, feel free to play with it.\n",
    "    However, we set this to be 15 by default due to our network is much smaller that suffers from learning high frequency features.\n",
    "    If you have time, make the hidden layers to 512 width with 5 depth, then checkout the difference.\n",
    "\n",
    "    By default, the weights for the first layer are initialized differently as suggested in Sec.3.2 in the original paper. We use is_first flag to\n",
    "    check whether we should init the weights differently.\n",
    "\n",
    "    We use linear layer as the last layer without any activation functions since SDF values shouldn't be limited to a certain range.\n",
    "    We use is_last flag to check if we should use activation functions or not.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, is_last=False, w0=15, skip_weight=1):\n",
    "        \"\"\"\n",
    "        In this function, you are tasked to initialize the fully-connectd layer self.fc using the feature vectors with their sizes specified by in_featuers and out_features\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        self.w0 = w0                         # a float specifying the default frequency in activation function \n",
    "        self.is_first = is_first             # a boolean flag indicating if the layer is the first layer\n",
    "        self.is_last = is_last               # a boolean flag indicating if the layer is the last layer\n",
    "        self.skip_weight = skip_weight       # a float weight controlling skip connection\n",
    "        self.in_features = in_features       # an integer specifying the size of the input feature vector\n",
    "        self.out_features = out_features     # an integer specifying the size of the output feature vector\n",
    "        self.fc = None                       # fully connected layer; None as default\n",
    "\n",
    "        ### your implementation starts\n",
    "                \n",
    "        ### your implementation ends\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        This function initializes the weights for the first layer and other layers (see details in the Deep SDF paper Sec.3.2).\n",
    "        No implementation is required in this function.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.fc.weight.uniform_(-1. / self.in_features,\n",
    "                                             1. / self.in_features)\n",
    "            else:\n",
    "                self.fc.weight.uniform_(-np.sqrt(6 / self.in_features) / self.w0,\n",
    "                                             np.sqrt(6 / self.in_features) / self.w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        You are tasked to implement the activation function by using the output of the fully connected layer taking x.\n",
    "        The implementation should consists of three cases: the first layer, the last layer, and the intermediate layer(s).\n",
    "            - If the layer is the first layer, you should apply the sine activation function to the output of the fully connected layer with w0 as its frequency;\n",
    "            - If the layer is the last layer, you should take the output of the fully connected layer as the final output;\n",
    "            - If the layer is an intermediate layer, you should add the output from the sine activation function weighted by skip_weight to the original x.\n",
    "        \"\"\"\n",
    "        ### your implementation starts\n",
    "        \n",
    "        ### your implementation ends\n",
    "\n",
    "class NeuralSDF(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, hidden_layers, out_features, w0=30):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        You are tasked to initialize all the layers in the neural network, including the first layer, the intermediate layer(s), and the last layer.\n",
    "        The initialized network layers will be stored in the list of nn.\n",
    "        Make sure to use the input arguments of the init function when initializing these layers. \n",
    "        \"\"\"\n",
    "\n",
    "        self.network = []                               # a list storing all the layers; empty by default\n",
    "        self.w0 = w0                                    # a float specifying the activation function frequency \n",
    "        self.hidden_features = hidden_features          # an integer specifying the size of the hidden-layer feature vector\n",
    "        self.hidden_layers = hidden_layers              # an integer specifying specifying the number of hidden layers\n",
    "        self.in_features = in_features                  # an integer specifying the size of the input feature vector\n",
    "        self.out_features = out_features                # an integer specifying the size of the output feature vector\n",
    "\n",
    "        ### your implementation starts\n",
    "        \n",
    "        ### your implementation ends\n",
    "        \n",
    "        self.network = nn.Sequential(*self.network)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.network(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c90b11e",
   "metadata": {},
   "source": [
    "## Step 1.4 Train Your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb654774-d60f-4f06-b374-9b5cc8ebe840",
   "metadata": {
    "id": "fb654774-d60f-4f06-b374-9b5cc8ebe840"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 1.4: Train Your Neural Network with Adam Optimizer\n",
    "\"\"\"\n",
    "def train_neuralSDF(dataloader, hidden_features, hidden_layers, w0, lr=1e-4, iterations=10000, device='cuda'):\n",
    "    \"\"\"\n",
    "    You are tasked to implement the training loop of the neural network. \n",
    "    For each epoch, you will start with a zero gradient and use the Mean Squared Loss (MSE) as your loss function. \n",
    "    Then, you need to propagate the loss backward and run the optimization step function provided by the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    model = NeuralSDF(in_features=3, out_features=1, hidden_features=hidden_features, hidden_layers=hidden_layers, w0=w0).to(device)\n",
    "    optimizer = torch.optim.Adam(lr=lr, params=model.parameters(), weight_decay=.0)\n",
    "    data, labels = next(iter(dataloader))\n",
    "\n",
    "    for epoch in range(iterations):\n",
    "\n",
    "        ### your implementation starts\n",
    "        \n",
    "        ### your implementation ends\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195eb13-77a7-45b5-baf1-d5b471cd4828",
   "metadata": {
    "id": "9195eb13-77a7-45b5-baf1-d5b471cd4828"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sample_num: total points sampled (feel free to increase this if needed)\n",
    "mesh_path: relative path to .obj file location\n",
    "\"\"\"\n",
    "\n",
    "sample_num = 300000  ### total number of points sampled as training points, feel free to change this.\n",
    "device='cuda'\n",
    "mesh_path=\"cow.obj\" ### mesh path to your mesh,\n",
    "\n",
    "sdf = NeuralSDFDataset(mesh_path, sample_num, device=device)\n",
    "sdfloader = DataLoader(sdf, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a405f-0728-407b-935a-af706e779e49",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "438a405f-0728-407b-935a-af706e779e49",
    "outputId": "206c2b72-333b-4fc7-c85b-3bda7f70e024"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hidden_features: hidden layer width.\n",
    "hidden_layers: hidden layer depth.\n",
    "w0: Activation frequency. We suggest 15 for our given examples.\n",
    "\n",
    "Feel free to play around with these parameters.\n",
    "\"\"\"\n",
    "hidden_features = 16 ### hidden layer width, feel free to change\n",
    "hidden_layers = 2 ### hidden layer depth, feel free to change\n",
    "w0 = 15 ### activation function frequency, feel free to change\n",
    "iterations = 10000 ### total number of training iterations, feel free to change\n",
    "lr = 1e-4 ### learning rate, feel free to change\n",
    "\n",
    "neural_sdf = train_neuralSDF(sdfloader, hidden_features = hidden_features, hidden_layers = hidden_layers, w0 = w0, lr=lr, iterations=iterations, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71626b5",
   "metadata": {},
   "source": [
    "## Step 2 Copy Network Weights to Shader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcd78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Run this step to generate the text file for the neural network weights. \n",
    "The generated weights will be printed to the Notebook output.\n",
    "There is no implementation requirement for this section.\n",
    "\n",
    "The neural SDF to ShaderToy conversion were modified based on Blackle Mori's Neural Stanford Bunny: https://www.shadertoy.com/view/wtVyWK\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "### Helper function for convert pytorch cuda tensor to numpy arrays\n",
    "def dump_data(dat):\n",
    "  dat = dat.cpu().detach().numpy()\n",
    "  return dat\n",
    "\n",
    "### Print a vector to a form that's usable in fragement shader\n",
    "def print_vec4(ws):\n",
    "  vec = \"vec4(\" + \",\".join([\"{0:.2f}\".format(w) for w in ws]) + \")\"\n",
    "  vec = re.sub(r\"\\b0\\.\", \".\", vec)\n",
    "  return vec\n",
    "\n",
    "### Print a matrix to a form that's usable in fragement shader\n",
    "def print_mat4(ws):\n",
    "  mat = \"mat4(\" + \",\".join([\"{0:.2f}\".format(w) for w in np.transpose(ws).flatten()]) + \")\"\n",
    "  mat = re.sub(r\"\\b0\\.\", \".\", mat)\n",
    "  return mat\n",
    "\n",
    "### Since we know networks are just matrices and vectors, this function converts our network to matrices and vectors that \n",
    "### can be compiled in fragement shader. \n",
    "def serialize_to_shadertoy(network, varname):\n",
    "  omega = network.w0\n",
    "  chunks = int(network.hidden_features/4)\n",
    "  lin = network.network[0].fc\n",
    "  in_w = dump_data(lin.weight)\n",
    "  in_bias = dump_data(lin.bias)\n",
    "  om = omega\n",
    "  for row in range(chunks):\n",
    "    line = \"vec4 %s0_%d=sin(\" % (varname, row)\n",
    "    for ft in range(network.in_features):\n",
    "        feature = x_vec = in_w[row*4:(row+1)*4,ft]*om\n",
    "        line += (\"p.%s*\" % [\"y\",\"z\",\"x\"][ft]) + print_vec4(feature) + \"+\"\n",
    "    bias = in_bias[row*4:(row+1)*4]*om\n",
    "    line += print_vec4(bias) + \");\"\n",
    "    print(line)\n",
    "\n",
    "  #hidden layers\n",
    "  for layer in range(network.hidden_layers):\n",
    "    layer_w = dump_data(network.network[layer+1].fc.weight)\n",
    "    layer_bias = dump_data(network.network[layer+1].fc.bias)\n",
    "    for row in range(chunks):\n",
    "      line = (\"vec4 %s%d_%d\" % (varname, layer+1, row)) + \"=sin(\"\n",
    "      for col in range(chunks):\n",
    "        mat = layer_w[row*4:(row+1)*4,col*4:(col+1)*4]*omega\n",
    "        line += print_mat4(mat) + (\"*%s%d_%d\"%(varname, layer, col)) + \"+\\n    \"\n",
    "      bias = layer_bias[row*4:(row+1)*4]*omega\n",
    "      line += print_vec4(bias)+\")/%0.1f+%s%d_%d;\"%(sqrt(layer+1), varname, layer, row)\n",
    "      print(line)\n",
    "\n",
    "  #output layer\n",
    "  out_w = dump_data(network.network[-1].fc.weight)\n",
    "  out_bias = dump_data(network.network[-1].fc.bias)\n",
    "  for outf in range(network.out_features):\n",
    "    line = \"return \"\n",
    "    for row in range(chunks):\n",
    "      vec = out_w[outf,row*4:(row+1)*4]\n",
    "      line += (\"dot(%s%d_%d,\"%(varname, network.hidden_layers, row)) + print_vec4(vec) + \")+\\n    \"\n",
    "    print(line + \"{:0.3f}\".format(out_bias[outf])+\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcebc6-c43a-4ff9-9a5f-622be22d03cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0fcebc6-c43a-4ff9-9a5f-622be22d03cf",
    "outputId": "e2278819-13b7-49f9-c5e5-294a63d8b641"
   },
   "outputs": [],
   "source": [
    "serialize_to_shadertoy(neural_sdf, 'f')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "hml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
